# -*- coding: utf-8 -*-
"""A4_main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nNR1n50cTjc6i7TG8p9hw2Cp_XKnYxMg
"""

from tensorflow import keras
from keras.models import Sequential
from keras import Input
from keras.layers import Dense
import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import gensim
from gensim.models import Word2Vec
import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
from nltk.util import pad_sequence
import pickle
from gensim.models import KeyedVectors
from keras.preprocessing.sequence import pad_sequences
from os import name
import tensorflow as tf
#from tensorflow.keras import activations
from keras import layers
from keras import regularizers
from keras.layers.embeddings import Embedding
from keras.layers import Dropout
from sklearn.feature_extraction.text import CountVectorizer


nltk.download('stopwords')

# add sys arg command line arguements here
print(sys.arg)
filepath = sys.argv[0]

#filepath = '/content/drive/MyDrive/MSCI 598'

# Positive Training Reviews without stopword removal
training_pos = filepath + '/train_pos.csv'
training_pos_ns = filepath + '/train_ns_pos.csv'
training_neg = filepath + '/train_neg.csv'
training_neg_ns = filepath + '/test_ns_neg.csv'
testing_pos = filepath + '/test_pos.csv'
testing_pos_ns = filepath + '/test_ns_pos.csv'
testing_neg = filepath + '/test_neg.csv'
testing_neg_ns = filepath + '/test_ns_neg.csv'

col = ['review']
training_pos_df = pd.read_csv(training_pos, delimiter = "\t", names=col)
training_pos_df_ns = pd.read_csv(training_pos_ns, delimiter = "\t", names=col)
training_neg_df = pd.read_csv(training_neg, delimiter = "\t", names=col)
training_neg_df_ns = pd.read_csv(training_neg_ns, delimiter = "\t", names=col)
testing_pos_df = pd.read_csv(testing_pos, delimiter = "\t", names=col)
testing_pos_ns_df = pd.read_csv(testing_pos_ns, delimiter = "\t", names=col)
testing_neg_df = pd.read_csv(testing_neg, delimiter = "\t", names=col)
testing_neg_ns_df = pd.read_csv(testing_neg_ns, delimiter = "\t", names=col)

training_pos_df['sentient'] = 1
training_pos_df_ns['sentient'] = 1
training_neg_df['sentient'] = 0
training_neg_df_ns['sentient'] = 0
testing_pos_df['sentient'] = 1
testing_pos_ns_df['sentient'] = 1
testing_neg_df['sentient'] = 0
testing_neg_ns_df['sentient'] = 0

training_pos_df['review'] = training_pos_df['review'].str.replace('\d+', '')
training_pos_df['review'] = training_pos_df['review'].apply(eval).apply(' '.join)
training_pos_df_ns['review'] = training_pos_df_ns['review'].str.replace('\d+', '')
training_pos_df_ns['review'] = training_pos_df_ns['review'].apply(eval).apply(' '.join)
training_neg_df['review'] = training_neg_df['review'].str.replace('\d+', '')
training_neg_df['review'] = training_neg_df['review'].apply(eval).apply(' '.join)
training_neg_df_ns['review'] = training_neg_df_ns['review'].str.replace('\d+', '')
training_neg_df_ns['review'] = training_neg_df_ns['review'].apply(eval).apply(' '.join)
testing_pos_df['review'] = testing_pos_df['review'].str.replace('\d+', '')
testing_pos_df['review'] = testing_pos_df['review'].apply(eval).apply(' '.join)
testing_pos_ns_df['review'] = testing_pos_ns_df['review'].str.replace('\d+', '')
testing_pos_ns_df['review'] = testing_pos_ns_df['review'].apply(eval).apply(' '.join)
testing_neg_df['review'] = testing_neg_df['review'].str.replace('\d+', '')
testing_neg_df['review'] = testing_neg_df['review'].apply(eval).apply(' '.join)
testing_neg_ns_df['review'] = testing_neg_ns_df['review'].str.replace('\d+', '')
testing_neg_ns_df['review'] = testing_neg_ns_df['review'].apply(eval).apply(' '.join)

train = pd.concat([training_pos_df, training_neg_df])
train_ns = pd.concat([training_pos_df_ns, training_neg_df_ns])
test = pd.concat([testing_pos_df, testing_neg_df])
test_ns = pd.concat([testing_pos_ns_df, testing_neg_ns_df])



reviews = []

for i in train['review']:
  li = list(i.split(" "))
  reviews.append(li)

word_2_vec_model = Word2Vec(sentences=reviews, window=5, min_count=1, workers=4)

word_vec = word_2_vec_model.wv
word_vec.save("word2vec.wordvectors")
wv = KeyedVectors.load("word2vec.wordvectors", mmap='r')
embeddings = word_2_vec_model.wv.get_keras_embedding(train_embeddings=False)
vocab_size = word_2_vec_model.wv.vectors.shape
print(word_2_vec_model)
print(len(max(reviews, key=len)))

X = word_2_vec_model[word_2_vec_model.wv.vocab]
print(X)

from tensorflow.keras.preprocessing import sequence
#max_review_length = 88
#X = sequence.pad_sequences(X, maxlen=max_review_length, padding='post', truncating='post')

encodedReviews = [word_2_vec_model.wv[word] for word in reviews]

encodedReviews = sequence.pad_sequences(encodedReviews, maxlen=86, padding='post', truncating='post')

#print(wv.vocab['computer'].index)
#print(X[849])
encodedReviews = [word_2_vec_model.wv[word] for word in reviews]
encodedReview = []
f=1

for i in reviews:

  for e in i:
    index = wv.vocab[e].index
    embedding = X[index]
    encodedReview.append(embedding)

  encodedReviews.append(encodedReview)
 # encodedReview.clear()

print(encodedReviews[0])

X_train = train_ns['review']

y_train = train_ns['sentient']

X_test = test_ns['review']

y_test = test_ns['sentient']

from keras.layers import Flatten

vectorizer = CountVectorizer().fit(train_ns)

#reluModel Creation
reluModel = Sequential(name='reluModel')
embeddingLayer = Embedding(4,32,input_length=86)
reluModel.add(embeddingLayer)
reluModel.add(Flatten())

#reluModel.add(Embedding(vocabSize, 64, input_length=4, name ='inputLayer'))
#reluModel.add(Input(shape=(1,), name ='inputLayer'))
#reluModel.add(Dense(10, input_dim = xTrain.shape[0], activation='sigmoid', name='hiddenLayer'))
reluModel.add(Dense(2, activation='softmax', name='outputLayer'))
L2layer = tf.keras.layers.Dense(5, kernel_initializer='ones',
                              activity_regularizer=tf.keras.regularizers.l2(0.01),
                              name='L2Layer')
reluModel.add(L2layer)
reluModel.add(Dropout(0.2, input_shape=(60,)))


reluModel.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    loss_weights=None, 
    weighted_metrics=None, 
    run_eagerly=None,
    steps_per_execution=None 
)

reluModel.fit(encodedReviews,y_train,batch_size=10)

predSentientTrain = (reluModel.predict(X_train)).astype(int)
predSentientTest = (reluModel.predict(X_test)).astype(int)

print("")
print('-------------------- Model Summary --------------------')
reluModel.summary() # print model summary
print("")
print('-------------------- Weights and Biases --------------------')
for layer in reluModel.layers:
    print("Layer: ", layer.name) # print layer name
    print("  --Kernels (Weights): ", layer.get_weights()[0]) # weights
    print("  --Biases: ", layer.get_weights()[1]) # biases
    
print("")
print('---------- Evaluation on Training Data ----------')
print(classification_report(y_train, predSentientTrain))
print("")

print('---------- Evaluation on Test Data ----------')
print(classification_report(y_test, predSentientTest))
print("")

